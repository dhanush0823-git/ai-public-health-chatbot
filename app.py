# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mf7_kCSBcBvC_K1pQl_pEYnawxYzSYRH
"""

import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
from transformers import MarianMTModel, MarianTokenizer
import torch

# ---------------------------
# CONFIG
# ---------------------------
st.set_page_config(page_title="SwasthyaBot", layout="wide")
st.title("ðŸ©º SwasthyaBot â€“ AI Health Chatbot")

# GitHub raw dataset links (replace USERNAME/REPO with your repo name)
FAQ_URL = "https://raw.githubusercontent.com/USERNAME/REPO/main/data/health_faq.csv"
VACCINE_URL = "https://raw.githubusercontent.com/USERNAME/REPO/main/data/vaccination.csv"
OUTBREAK_URL = "https://raw.githubusercontent.com/USERNAME/REPO/main/data/outbreak.csv"

# ---------------------------
# Load datasets
# ---------------------------
@st.cache_data
def load_dataset(url, category):
    df = pd.read_csv(url)
    df["category"] = category
    return df

faq_df = load_dataset(FAQ_URL, "Health FAQ")
vaccine_df = load_dataset(VACCINE_URL, "Vaccination")
outbreak_df = load_dataset(OUTBREAK_URL, "Outbreak Alert")

# Merge all into one knowledge base
kb = pd.concat([faq_df, vaccine_df, outbreak_df], ignore_index=True)

# ---------------------------
# Embedding model
# ---------------------------
@st.cache_resource
def load_embedder():
    return SentenceTransformer("all-MiniLM-L6-v2")

embedder = load_embedder()
kb_embeddings = embedder.encode(kb["question"].tolist(), convert_to_tensor=True)

# ---------------------------
# Translation utilities
# ---------------------------
@st.cache_resource
def load_translator(src_lang, tgt_lang):
    model_name = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
    tok = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name)
    return tok, model

def translate(text, src_lang, tgt_lang):
    if src_lang == tgt_lang:
        return text
    try:
        tok, model = load_translator(src_lang, tgt_lang)
        batch = tok.prepare_seq2seq_batch([text], return_tensors="pt")
        gen = model.generate(**batch)
        return tok.decode(gen[0], skip_special_tokens=True)
    except Exception:
        return text  # fallback

# ---------------------------
# Search function
# ---------------------------
def get_answer(query, lang="en"):
    # Translate query -> English
    q_en = translate(query, lang, "en")
    # Embed query
    q_emb = embedder.encode(q_en, convert_to_tensor=True)
    # Find most similar
    scores = util.pytorch_cos_sim(q_emb, kb_embeddings)[0]
    best_idx = torch.argmax(scores).item()
    best_q = kb.iloc[best_idx]["question"]
    best_a = kb.iloc[best_idx]["answer"]
    best_cat = kb.iloc[best_idx]["category"]
    # Translate back to user language
    ans_out = translate(best_a, "en", lang)
    return ans_out, best_q, best_cat

# ---------------------------
# Chat UI
# ---------------------------
if "history" not in st.session_state:
    st.session_state.history = []

lang = st.selectbox("Choose your language", ["en", "hi", "ta", "te", "mr", "bn"])

user_input = st.text_input("Ask me about health, vaccination, or outbreaks:")

if st.button("Ask"):
    if user_input.strip():
        ans, ref_q, cat = get_answer(user_input, lang)
        st.session_state.history.append((user_input, ans, ref_q, cat))

# Show conversation
for q, a, ref, cat in st.session_state.history:
    st.markdown(f"ðŸ‘¤ **You:** {q}")
    st.markdown(f"ðŸ¤– **SwasthyaBot:** {a}")
    st.caption(f"(matched from: *{ref}* in {cat})")
    st.write("---")